{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b223c90",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe <br> Zadanie domowe nr 1: Klasyfikacja wektorów nośnych i regresja logistyczna - z elementami konkursu\n",
    "Politechnika Gdańska, Wydział ETI, Katedra Inżynierii Biomedycznej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222f2fe",
   "metadata": {},
   "source": [
    "# Cel:\n",
    "Opracować procedurę złożoną z przetwarzania wstępnego oraz klasyfikacji danych z wykorzystaniem sieci neuronowych (uwaga - jedynie MLP - bez CNN, itp.) w celu uzyskania jak najlepszych wyników klasyfikacji dla zadanego zbioru danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3c46b",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "Dla zbioru CIFAR-10 należy wybrać przykłady dla wskazanych 3 klas. Następnie opracować procedurę w celu uzyskania najlepszych wyników klasyfikacji mierzonych z użyciem miary F1-score, F1 = 2(recall*precision)/(recall+precision). Do wyznaczenia wartości miary należy zastosować funkcję f1_score z pakietu scikit-learn (from sklearn.metrics import f1_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103633b",
   "metadata": {},
   "source": [
    "# Dane studentów\n",
    "10.05.2021 <br>\n",
    "Inżynieria biomedyczna, Sztuczna inteligencja gr. 1 <br>\n",
    "Patrycja Gładkowska 171951 <br>\n",
    "Szymon Sadowski 165298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb672a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and select classes 'plane', 'cat', 'truck'\n",
    "\n",
    "import random\n",
    "from keras.datasets import cifar10\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "# indexes = [0, 3, 9]\n",
    "\n",
    "# idx_train = np.array([idx for idx in range(y_train.shape[0]) if y_train[idx] in indexes])\n",
    "# idx_test = np.array([idx for idx in range(y_test.shape[0]) if y_test[idx] in indexes])\n",
    "\n",
    "# x_train = X_train[idx_train]\n",
    "# y_train = y_train[idx_train]\n",
    "\n",
    "# x_test = X_test[idx_test]\n",
    "# y_test = y_test[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f4e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5c814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,939,338\n",
      "Trainable params: 3,939,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 16ms/step - loss: 2.3030 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "# MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b3abcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.302593469619751\n",
      "Test acc: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf3c3539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]\n",
      " [1000    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Recall and precision values per class:\n",
      "Recall: \n",
      " [100.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Precision: \n",
      " [10. nan nan nan nan nan nan nan nan nan]\n",
      "Mean recall:  10.0\n",
      "Mean precision:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-859ae55a1a68>:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (tp/(tp+fp))\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "y = model.predict(X_test)\n",
    "\n",
    "# Transform \"probabilities\" to class codes\n",
    "det = tf.cast((y+0.5), tf.int32)\n",
    "detections = tf.cast(det, tf.float32)\n",
    "\n",
    "# Change one-hot encoded value into simple class code values\n",
    "y_t = np.argmax(Y_test, axis=1)\n",
    "y_p = np.argmax(detections, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "# (y_true, y_pred) -> the rows represent true labels, columns predictions\n",
    "cm = tf.math.confusion_matrix(y_t, y_p) \n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm.numpy())\n",
    "\n",
    "# Define functions to count TP, FP, FN, recall and precision for each class\n",
    "\n",
    "def false_positives(conf_matrix):\n",
    "    sums = np.sum(conf_matrix, axis=0) # sum for rows\n",
    "    fp = np.subtract(sums, np.diagonal(conf_matrix))\n",
    "    return fp\n",
    "\n",
    "def false_negatives(conf_matrix):\n",
    "    sums = np.sum(conf_matrix, axis=1)  # sum for columns\n",
    "    fn = np.subtract(sums, np.diagonal(conf_matrix))\n",
    "    return fn\n",
    "\n",
    "def recall (conf_matrix):\n",
    "    tp = np.diagonal(conf_matrix)\n",
    "    fn = false_negatives(conf_matrix)\n",
    "    return (tp/(tp+fn))\n",
    "  \n",
    "def precision (conf_matrix):\n",
    "    tp = np.diagonal(conf_matrix)\n",
    "    fp = false_positives(conf_matrix)\n",
    "    return (tp/(tp+fp))\n",
    "\n",
    "print(\"\\nRecall and precision values per class:\")\n",
    "print(\"Recall: \\n\", 100*recall(cm))\n",
    "print(\"Precision: \\n\", 100*precision(cm))\n",
    "\n",
    "print(\"Mean recall: \", 100*np.mean(recall(cm)))\n",
    "print(\"Mean precision: \", 100*np.mean(precision(cm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "# pred_test = model.predict(x_test)\n",
    "\n",
    "# accuracy_test = model.score(x_test, y_test)\n",
    "# print(f\"Accuracy: {accuracy_test}\")\n",
    "\n",
    "# print(\"Confusion matrix:\")\n",
    "# conf_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "# print(conf_matrix_test)\n",
    "\n",
    "# f1_score_test = f1_score(y_test, pred_test, average=\"weighted\")\n",
    "# print(f\"F1 score: {f1_score_test}\")\n",
    "\n",
    "# print(\"Classification report:\")\n",
    "# classification_report_test = classification_report(y_test, pred_test, target_names=target_names)\n",
    "# print(classification_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_example_id = random.randrange(len(idx_test))\n",
    "# size = X_te.shape[1]\n",
    "# t = (X_te[test_example_id]).reshape((1,size))\n",
    "\n",
    "# pred_t = model.predict(t)\n",
    "\n",
    "# print(f\"Class names: {target_names}\")\n",
    "# print(f\"Predicted class code: {pred_t}\")\n",
    "# print(f\"Predicted class label: {class_names[pred_t[0]]}\")\n",
    "\n",
    "# scores = model.decision_function(t)\n",
    "# print(f\"Scores for each class: {scores}\")\n",
    "\n",
    "# example_test_true_label = class_names[y_test[idx_test[test_example_id]][0]]\n",
    "# print(f\"True label: {example_test_true_label}\")\n",
    "\n",
    "# example_test_image = x_test[idx_test[test_example_id],:,:,:]\n",
    "# plt.imshow(example_test_image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd889c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your data\n",
    "# X_test = ''\n",
    "# y_test_reduced = ''\n",
    "\n",
    "# pred_test_extra = model.predict(X_test)\n",
    "\n",
    "# accuracy_test_extra = model.score(X_test, y_test_reduced)\n",
    "# print(f\"Accuracy: {accuracy_test_extra}\")\n",
    "\n",
    "# print(\"Confusion matrix:\")\n",
    "# conf_matrix_test_extra = confusion_matrix(y_test_reduced, pred_test_extra)\n",
    "# print(conf_matrix_test_extra)\n",
    "\n",
    "# f1_score_test_extra = f1_score(y_test_reduced, pred_test_extra, average=\"weighted\")\n",
    "# print(f\"F1 score: {f1_score_test_extra}\")\n",
    "\n",
    "# print(\"Classification report:\")\n",
    "# classification_report_test_extra = classification_report(y_test_reduced, pred_test_extra, target_names=target_names)\n",
    "# print(classification_report_test_extra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
